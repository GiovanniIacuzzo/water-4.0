**Simulatore intelligente per addestramento e testing di algoritmi di leakage detection**

---

## 🛠️ Obiettivo del progetto (in sintesi)

**Costruire un sistema che genera scenari realistici di perdite idriche** all’interno della rete L-TOWN (BattLeDIM) usando:

* Il modello idraulico EPANET (`.inp`)
* I dati reali del 2018 (SCADA + AMR)
* Algoritmi AI/statistici per simulare *scenari credibili e variegati*
* Output: dataset di leak simulati → utili per testare modelli ML/AI

---

## 📍 PIPELINE

---

### **🔧 Fase 0. Setup**

✅ Obiettivo: Ambiente pronto

* [ ] Installare EPANET toolkit (preferibilmente `epanettools` o `WNTR` in Python)
* [ ] Importare rete `.inp` e verificarne l’integrità
* [ ] Caricare i dati SCADA e AMR (normalizzazione + parsing timestamp)

---

### **🔍 Fase 1. Analisi esplorativa**

✅ Obiettivo: Capire i dati reali e calcolare statistiche di riferimento

* [ ] Analizzare i pattern reali di flusso e pressione (range, media, varianza)
* [ ] Individuare giorni “tipici” e “anomali”
* [ ] Calcolare profili di consumo (hourly/daily)
* [ ] Costruire una baseline "senza perdite"

---

### **🧪 Fase 2. Iniezione di perdite**

✅ Obiettivo: Costruire uno script che inietta perdite nel modello EPANET

* [ ] Scegliere un nodo o tratto di condotta
* [ ] Definire tipo di perdita: **orifizio, valvola aperta, tubo rotto** (EPANET supporta tutti)
* [ ] Parametri:

  * Posizione
  * Inizio e fine della perdita (timestamp)
  * Severità (coefficiente di perdita/orifizio)
* [ ] Simulare l'effetto sul sistema idraulico

> 🔄 Output: Serie temporale modificata con la perdita simulata

---

### **🧠 Fase 3. Motore AI per generare scenari**

✅ Obiettivo: Creare una funzione che generi automaticamente **scenari credibili**

* [ ] Input: regole o modelli generativi

  * Dati storici → estrazione di pattern reali
  * Distribuzioni di orari, entità e durata delle perdite
* [ ] Output:

  * Set di perdite con parametri realistici
* [ ] Approccio possibile:

  * Modello statistico (ex: distribuzione oraria + severità)
  * O AI generativa (opzionale): es. GAN o VAE per “imparare” pattern anomali

---

### **📤 Fase 4. Generazione del dataset**

✅ Obiettivo: Creare un dataset in formato leggibile per modelli ML

* [ ] Simulare per ogni scenario:

  * Serie temporali di pressione e flusso
  * Con e senza perdite
* [ ] Generare etichette (`leak = 0/1`) e metadati:

  * Timestamp
  * Nodo/condotta coinvolta
  * Severità
* [ ] Organizzare in formato `.csv` / `.h5` / `.npz` / `.parquet`

---

### **📈 Fase 5. Visualizzazione & Validazione**

✅ Obiettivo: Validare visivamente l’effetto delle perdite

* [ ] Grafici prima/dopo (flusso e pressione)
* [ ] Heatmap della rete con posizione perdite
* [ ] Statistiche aggregate (range di deviazione rispetto al normale)

---

### **🤖 Fase 6. Benchmark ML (opzionale ma consigliata)**

✅ Obiettivo: Usare il dataset per testare modelli

* [ ] Applica modelli classici:

  * Isolation Forest
  * Autoencoder
  * Random Forest
* [ ] Confronta con il ground truth
* [ ] Valuta metriche: precision, recall, F1-score, ROC-AUC

---

### **📄 Fase 7. Output e documentazione**

✅ Obiettivo: Produrre materiale esportabile

* [ ] Codice commentato + README
* [ ] Dataset `.zip` con licenza
* [ ] Report tecnico (PDF / Jupyter)
* [ ] Opzionale: notebook Google Colab

---

### **🌐 Fase 8. (Bonus)** – Interfaccia Web semplice

✅ Obiettivo: GUI per testare e visualizzare scenari

* [ ] Dashboard interattiva con:

  * Selettore di nodi
  * Slider per severità e durata
  * Grafici e heatmap live

---